from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import requests
import os
import logging
import time
time.sleep(0.5)  # Esperar medio segundo antes de enviar la respuesta completa


# Configurar logs
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Cargar la API Key de Humata AI y el document_id desde las variables de entorno
HUMATA_API_KEY = os.getenv("HUMATA_API_KEY")  # API Key
DOCUMENT_ID = os.getenv("HUMATA_DOCUMENT_ID")  # Documento al que se har√° preguntas
CREATE_CONVERSATION_ENDPOINT = "https://app.humata.ai/api/v1/conversations"  # Endpoint para crear conversaci√≥n
ASK_ENDPOINT = "https://app.humata.ai/api/v1/ask"  # Endpoint para preguntar en la conversaci√≥n

app = FastAPI()

# Habilitar CORS para permitir solicitudes desde el frontend espec√≠fico
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://nelefrenn.github.io"],  # Permitir solo el frontend
    allow_credentials=True,
    allow_methods=["GET", "POST", "OPTIONS"],  # M√©todos permitidos
    allow_headers=["Content-Type", "Authorization"],  # Permitir solo encabezados necesarios
)

# Ruta ra√≠z para comprobar que el backend funciona
@app.get("/")
@app.head("/")
def home():
    return {"message": "Bienvenido al backend del Asistente Virtual IDCBIS"}

class ChatRequest(BaseModel):
    message: str

# Funci√≥n para crear una nueva conversaci√≥n con el documento
import json

def create_conversation():
    headers = {
        "Authorization": f"Bearer {HUMATA_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "documentIds": [DOCUMENT_ID]  # Crear conversaci√≥n con el documento
    }

    logger.info(f"Creando nueva conversaci√≥n con Humata AI usando DOCUMENT_ID: {DOCUMENT_ID}")
    response = requests.post(CREATE_CONVERSATION_ENDPOINT, json=payload, headers=headers)

    # üîç Imprimir la respuesta cruda antes de convertirla a JSON
    logger.info(f"Respuesta cruda de Humata AI: {response.status_code} - {response.text}")

    if response.status_code == 200:
        try:
            conversation_data = json.loads(response.text)

            # üîç Verificar tipo de dato de la respuesta
            logger.info(f"Tipo de respuesta JSON: {type(conversation_data)} - Contenido: {conversation_data}")

            # üî• FIX: Extraer "id" y mapearlo como "conversationId"
            conversation_id = conversation_data.get("id")  # Ahora tomamos "id"

            if conversation_id:
                logger.info(f"‚úÖ Conversaci√≥n creada con ID: {conversation_id}")
                return conversation_id
            else:
                logger.error("‚ùå No se encontr√≥ 'id' en la respuesta de Humata AI")
                logger.error(conversation_data)
                return None

        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Error al convertir la respuesta a JSON: {str(e)} - Respuesta: {response.text}")
            return None

    else:
        logger.error(f"‚ùå Error al crear conversaci√≥n: C√≥digo {response.status_code} - {response.text}")
        return None


import time
import json

@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    if not HUMATA_API_KEY:
        logger.error("API Key no configurada. Verifica las variables de entorno en Render.")
        raise HTTPException(status_code=500, detail="API Key no configurada. Verifica las variables de entorno en Render.")
    
    if not DOCUMENT_ID:
        logger.error("DOCUMENT_ID no configurado. Verifica las variables de entorno en Render.")
        raise HTTPException(status_code=500, detail="DOCUMENT_ID no configurado. Verifica las variables de entorno en Render.")
    
    conversation_id = create_conversation()
    if not conversation_id:
        raise HTTPException(status_code=500, detail="No se pudo crear la conversaci√≥n con Humata AI. Verifica el DOCUMENT_ID y los logs.")

    # üî• Esperar 1 segundo antes de hacer la pregunta (para evitar problemas de sincronizaci√≥n)
    time.sleep(1)

    try:
        headers = {
            "Authorization": f"Bearer {HUMATA_API_KEY}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "conversationId": conversation_id,  
            "question": request.message,
            "model": "gpt-4-turbo-preview",
            "selectedAnswerApproach": "Grounded"
        }
        
        logger.info(f"Preguntando a Humata AI con payload: {payload}")
        response = requests.post(ASK_ENDPOINT, json=payload, headers=headers, stream=True)

        # üîç Registrar c√≥digo de respuesta de Humata
        logger.info(f"üîç C√≥digo de respuesta de Humata AI: {response.status_code}")

        if response.status_code != 200:
            logger.error(f"‚ùå Error en Humata AI: C√≥digo {response.status_code} - Respuesta: {response.text}")
            raise HTTPException(status_code=response.status_code, detail=f"Error de Humata AI: {response.text}")

        # üî• Leer la respuesta en streaming y ensamblar correctamente el texto
        answer_parts = []
        last_word = ""  # Para reconstruir palabras cortadas

        for line in response.iter_lines():
            if line:
                try:
                    line_data = line.decode("utf-8").replace("data: ", "").strip()
                    json_data = json.loads(line_data)  # Convertir string a JSON
                    content = json_data.get("content", "")

                    # Si hay una palabra cortada del fragmento anterior, unirla con la nueva
                    if last_word:
                        content = last_word + content
                        last_word = ""

                    # Verificar si el contenido parece una palabra incompleta
                    if len(content) <= 3 and not content.endswith(" "):
                        last_word = content  # Guardar fragmento incompleto para unirlo con el siguiente
                    else:
                        answer_parts.append(content)

                except Exception as e:
                    logger.error(f"Error al procesar chunk de Humata AI: {str(e)} - Datos: {line}")

        # Si queda un fragmento en last_word, agregarlo al final
        if last_word:
            answer_parts.append(last_word)

        # Unir los fragmentos correctamente y limpiar el texto
        final_answer = "".join(answer_parts)  # üî• Eliminamos espacios extra
        final_answer = " ".join(final_answer.split())  # üî• Normalizamos los espacios

        logger.info(f"‚úÖ Respuesta limpia de Humata AI: {final_answer}")

        return {"reply": final_answer}

    except requests.exceptions.RequestException as e:
        logger.error(f"‚ùå Error en la solicitud a Humata AI: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error en la solicitud a Humata AI: {str(e)}")

    except Exception as e:
        logger.error(f"‚ùå Error inesperado: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error inesperado: {str(e)}")

